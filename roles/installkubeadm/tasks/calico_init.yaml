- name: Check calico installed
  when: "'control_plane' in group_names"
  ansible.builtin.shell: kubectl calico version | grep "Cluster Version"
  failed_when: False
  changed_when: False
  register: calico_result
  
- name: Install Calico in control_plane
  when:
    - "'control_plane' in group_names"
    - calico_result.stdout_lines | count == 0
  block:
    - name: Install calico, add helm repo (1/5)
      kubernetes.core.helm_repository:
        name: projectcalico
        repo_url: "https://projectcalico.docs.tigera.io/charts"

    - name: Install calico, copy values (2/5)
      ansible.builtin.template:
        src: "{{ role_path }}/templates/calico_helm_values.yaml.j2"
        dest: /etc/kubernetes/helm_values/calico.yaml
        owner: root
        group: root
        mode: 0640

    - name: Install calico, install chart (3/5)
      kubernetes.core.helm:
        update_repo_cache: True
        release_name: calico
        release_namespace: tigera-operator
        create_namespace: True
        chart_ref: projectcalico/tigera-operator
        atomic: True
        chart_version: "{{ calico_version }}"
        values_files:
          - /etc/kubernetes/helm_values/calico.yaml
        wait: True

    - name: Install Calico, fetch calicoctl (4/5)
      ansible.builtin.get_url:
        url: "{{ calicoctl_url }}"
        checksum: "{{ calicoctl_checksum }}"
        dest: /usr/local/bin/kubectl-calico
        mode: 0751
        owner: root
        group: root

    - name: Install Calico, sleep before continuing (5/5)
      # There are calico-apiserver and calico-system components that are indirectly created by the tigera-operator pod,
      # so the helm command doesn't wait for them to reach ready state.
      ansible.builtin.shell: sleep 45


- name: Configure IP pools
  when:
    - "'control_plane' in group_names"
  block:
    # There are two goals.
    # 1) Create an IP pool for the vlan subnet for traffic to the silos from the pods
    # so that source network address translation won't be performed on traffic to the silos.
    # see https://projectcalico.docs.tigera.io/networking/workloads-outside-cluster
    # 2) Create a separate IP pool for each node,
    # so that a short list of static routes can be applied to the silos to route traffic back to the pods.
    # see https://projectcalico.docs.tigera.io/networking/assign-ip-addresses-topology

    - name: Configure IP pools, wait until calico apiserver is ready (1/4)
      kubernetes.core.k8s:
        wait: True
        wait_condition:
          type: Available
          status: "True"
        api_version: v1
        kind: Deployment
        name: calico-apiserver
        namespace: calico-apiserver
        state: present

    - name: Configure IP pools, delete default pool (2/4)
      kubernetes.core.k8s:
        kubeconfig: "{{ k8s_admin_config }}"
        wait: True
        state: absent
        name: default-ipv4-ippool
        kind: IPPool
        api_version: projectcalico.org/v3

    - name: Configure IP pools, copy manifest (3/4)
      ansible.builtin.template:
        src: "{{ role_path }}/templates/calico_ip_pools.yaml.j2"
        dest: /etc/kubernetes/custom_manifests/calico_ip_pools.yaml
        owner: root
        group: root
        mode: 0640

    - name: Configure IP pools, apply manifest (4/4)
      kubernetes.core.k8s:
        kubeconfig: "{{ k8s_admin_config }}"
        apply: True
        src: /etc/kubernetes/custom_manifests/calico_ip_pools.yaml
        wait: True
